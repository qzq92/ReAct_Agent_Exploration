from typing import Union, List
from textwrap import dedent
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema import AgentAction, AgentFinish
from langchain.tools import Tool, tool
from langchain.tools.render import render_text_description
from langchain.agents.output_parsers import ReActSingleInputOutputParser
from langchain.agents.format_scratchpad.log import format_log_to_str

load_dotenv()

# tool decorator that converts function to langchain Tool object
@tool
def get_text_length(text: str) -> int:
    """Returns the length of a text by characters upon stripping newlines, single/double quotation marks."""
    print(f"get_text_length enter with {text=}")
    text = text.strip("'\n").strip(
        '"'
    )  # stripping away non alphabetic characters just in case

    return len(text)

def find_tool_by_name(tools: List[Tool], tool_name: str) -> Tool:
    """Returns tool information if provided tool_name is found in list of tools provided.

    Args:
        tools (List[Tool]): List of tool objects.
        tool_name (str): Tool name to be searched for.

    Raises:
        ValueError: When specified tool is not found.

    Returns:
        Tool: Tool object when required tool is found.
    """
    for tool in tools:
        if tool.name == tool_name:
            return tool
    raise ValueError(f"Tool with name {tool_name} not found")


if __name__ == "__main__":
    print("Test ReAct LangChain")

    # Contains list of tools
    tools = [get_text_length]

    # Template obtained from https://smith.langchain.com/hub/hwchase17/react. All variables within are to be in string format and nothing else. Strip whitespaces in template with dedent library to allow llm to find stop words like Observation. This also helps parser to parse output generated with correct stopping.
    template = dedent(
        """\
            Answer the following questions as best you can. You have access to the following tools:
            
            {tools}
            
            Use the following format:
            
            Question: the input question you must answer
            Thought: you should always think about what to do
            Action: the action to take, should be one of [{tool_names}]
            Action Input: the input to the action
            Observation: the result of the action
            ... (this Thought/Action/Action Input/Observation can repeat N times)
            Thought: I now know the final answer
            Final Answer: the final answer to the original input question
            
            Begin!
            
            Question: {input}
            Thought: {agent_scratchpad}"""
    )

    # Convert template to prompt template with partial variables(non-user inputs). When passing tools, we have to render tool name and description into text
    prompt = PromptTemplate.from_template(template=template).partial(
        tools=render_text_description(tools),
        tool_names=", ".join([t.name for t in tools]),
    )

    # Tell LLM to avoid creative answer ,and stop generating words once it reaches 'observation' as its output before reaching final answer. Firstly, it is to ensure alignment with the input expected of parser.
    llm=ChatOpenAI(temperature=0, model_kwargs={"stop":["\nObservation", "Observation"]})

    # History to be used by agents
    intermediate_steps = []
    # LCEL where we fit in variables to prompt using lambda function, which in turn will be fed to llm and output parser. Note that the output parser only accepts a particular output generated by llm, otherwise EXPECT errors. Variables must be in string format and not others.
    agent = (
        {"input": lambda x: x["input"],
         "agent_scratchpad": lambda x: format_log_to_str(intermediate_steps=x["agent_scratchpad"]),
        }
        | prompt
        | llm
        | ReActSingleInputOutputParser()
    )
    
    # Use invoke to test a given input. Ideally when doing invoke it should either have final answer or a parsible action/action input and not both.

    # Notes: langchain_core.exceptions.OutputParserException: Parsing LLM output produced both a final answer and a parse-able action:: indicates you get post parsable action and answer at the same time, confusing the LLM on what to do. From my experience working with agents I noticed that subtle changes like changing a couple of words/ characters can make a difference when working on a specific usecase.
    
    # Eventually after some time "wiggeling" with the prompt and doing a bit of prompt engineering I came out with this prompt. Why is it working and failing here and there ? because LLMs are statistical creatures and are not idempotent and we cannot assume that we will get the same output for the same input.
    agent_step: Union[AgentAction,AgentFinish] = agent.invoke(
        {
            "input": "What is the length in characters of the text DOG?",
            "agent_scratchpad": intermediate_steps,
        }
    )
    print(agent_step)
    
    # Identify the tool use when agent is taking actions
    if isinstance(agent_step, AgentAction):
        # Get info on tool name used by agent
        tool_name = agent_step.tool
        tool_to_use = find_tool_by_name(tools=tools,tool_name=tool_name)
        tool_input = agent_step.tool_input

        # Get observation
        observation = tool_to_use.func(str(tool_input))
        print(f"{observation=}")
        print("Updating history with observation")

        # Update history with agentaction and string as tuple
        intermediate_steps.append((agent_step, str(observation)))

    print("Invoking agent action with known steps")
    # Repeat to see the changes. ReAct Loop with history
    agent_step: Union[AgentAction,AgentFinish] = agent.invoke(
        {"input": "What is the length in characters of the text DOG?",
         "agent_scratchpad": intermediate_steps,
        }
    )
    print(agent_step)
    if isinstance(agent_step, AgentFinish):
        print(agent_step.return_values)
