from typing import Union, List

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema import AgentAction, AgentFinish
from langchain.tools import Tool, tool
from langchain.tools.render import render_text_description
from langchain.agents.output_parsers import ReActSingleInputOutputParser


load_dotenv()

# tool decorator that converts function to langchain Tool object
@tool
def get_text_length(text: str) -> int:
    """Returns the length of a text by characters upon stripping newlines, single/double quotation marks."""
    print(f"get_text_length enter with {text=}")
    text = text.strip("'\n").strip(
        '"'
    )  # stripping away non alphabetic characters just in case

    return len(text)

def find_tool_by_name(tools: List[Tool], tool_name: str) -> Tool:
    """Returns tool information if provided tool_name is found in list of tools provided.

    Args:
        tools (List[Tool]): List of tool objects.
        tool_name (str): Tool name to be searched for.

    Raises:
        ValueError: When specified tool is not found.

    Returns:
        Tool: Tool object when required tool is found.
    """
    for tool in tools:
        if tool.name == tool_name:
            return tool
    raise ValueError(f"Tool with name {tool_name} not found")


if __name__ == "__main__":
    print("Test ReAct LangChain")

    # Contains list of tools
    tools = [get_text_length]

    # Template obtained from https://smith.langchain.com/hub/hwchase17/react
    template = """
    Answer the following questions as best you can. You have access to the following tools:

    {tools}

    Use the following format:

    Question: the input question you must answer
    Thought: you should always think about what to do
    Action: the action to take, should be one of [{tool_names}]
    Action Input: the input to the action
    Observation: the result of the action
    ... (this Thought/Action/Action Input/Observation can repeat N times)
    Thought: I now know the final answer
    Final Answer: the final answer to the original input question

    Begin!

    Question: {input}
    Thought:
    """

    # Convert template to prompt template with partial variables(non-user inputs). When passing tools, we have to render tool name and description into text
    prompt = PromptTemplate.from_template(template=template).partial(
        tools=render_text_description(tools),
        tool_names=", ".join([t.name for t in tools]),
    )

    # Tell LLM to avoid creative answer ,and stop generating words once it reaches observation as its output. Firstly, it is to ensure alignment with the input expected of parser. Not putting means it will hallucinate by generating text and going to guess one word after another observation (result of the tool) and results in error when fed to parser.
    llm=ChatOpenAI(temperature=0, model_kwargs={"stop":["\nObservation"]})
    
    # LCEL where we fit in variables to prompt using lambda function, which in turn will be fed to llm and output parser. Note that the output parser only accepts a particular output generated by llm, otherwise EXPECT errors.
    agent = {"input": lambda x: x["input"]} |prompt | llm | ReActSingleInputOutputParser()
    
    # Use invoke to test a given input
    agent_step: Union[AgentAction,AgentFinish] = agent.invoke({"input": "What is the length in terms of number of characters of the word: Bangkok ?"})
    
    # Identify the tool use when agent is taking actions
    if isinstance(agent_step, AgentAction):
        # Get info on tool name used by agent
        tool_name = agent_step.tool
        tool_to_use = find_tool_by_name(tools=tools,tool_name=tool_name)
        tool_input = agent_step.tool_input
        print("Tool name:", tool_name)
        print("Tool to use:", tool_to_use)
        print("Tool input:", tool_input)
        # Get observation
        observation = tool_to_use.func(str(tool_input))
        print(f"{observation}")